{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('/home/brian/Documents/nlp_tweets.csv', encoding='ISO-8859-1', header = None)\n",
    "df.columns = ['IDK', 'tweetId', 'Datetime', 'Query?', 'Username', 'tweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\n",
    "sample = df.tweet[4]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 3),\n",
       " ('all', 2),\n",
       " ('i', 2),\n",
       " ('@', 1),\n",
       " ('nationwideclass', 1),\n",
       " ('no', 1),\n",
       " (',', 1),\n",
       " ('it', 1),\n",
       " (\"'s\", 1),\n",
       " ('not', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize\n",
    "\n",
    "from nltk import word_tokenize, FreqDist\n",
    "\n",
    "def tokenz(text, n):\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    freq_distro = FreqDist(tokens)\n",
    "\n",
    "    return freq_distro.most_common(n)\n",
    "\n",
    "tokenz(df.tweet[4], 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [@, switchfoot, http, :, //twitpic.com/2y1zl, ...\n",
       "1    [upset, ca, n't, update, Facebook, texting, .....\n",
       "2    [@, Kenichan, dived, many, times, ball, ., Man...\n",
       "3              [whole, body, feels, itchy, like, fire]\n",
       "4    [@, nationwideclass, ,, 's, behaving, ., 'm, m...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------REMOVE STOPWORDS---------------\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def stopword_remover(str):\n",
    "    tokens = word_tokenize(str)\n",
    "\n",
    "    eng_stopwords = stopwords.words('english')\n",
    "\n",
    "    return [word for word in tokens if word.lower() not in eng_stopwords]\n",
    "\n",
    "        \n",
    "df.tweet.head(5).apply(stopword_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [switchfoot, http, Awww, bummer, shoulda, got,...\n",
       "1    [upset, ca, update, Facebook, texting, might, ...\n",
       "2    [Kenichan, dived, many, times, ball, Managed, ...\n",
       "3              [whole, body, feels, itchy, like, fire]\n",
       "4            [nationwideclass, behaving, mad, ca, see]\n",
       "5                              [Kwesidei, whole, crew]\n",
       "6                                          [Need, hug]\n",
       "7    [LOLTrish, hey, long, time, see, Yes, Rains, b...\n",
       "8                                               [nope]\n",
       "9                               [twittera, que, muera]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------REMOVE NONALPHABETS--------------------\n",
    "def non_alpha_remover(str):\n",
    "    return [x for x in stopword_remover(str) if x.isalpha()]\n",
    "\n",
    "df.tweet.head(10).apply(non_alpha_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.962963\n",
       "1    1.000000\n",
       "2    1.000000\n",
       "3    1.000000\n",
       "4    0.866667\n",
       "5    1.000000\n",
       "6    1.000000\n",
       "7    0.857143\n",
       "8    1.000000\n",
       "9    1.000000\n",
       "Name: tweet, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------DETERMINE COMPLEXITY----------------------\n",
    "\n",
    "def det_complexity(str):\n",
    "    all_tokens = word_tokenize(str)\n",
    "\n",
    "    uniq_tokens = set(word_tokenize(str))\n",
    "\n",
    "    complexity = len(uniq_tokens) / len(all_tokens)\n",
    "    \n",
    "    return complexity\n",
    "\n",
    "df['tweet'].head(10).apply(det_complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (0.2, 0.6)\n",
       "1     (0.0, 0.0)\n",
       "2     (0.5, 0.5)\n",
       "3     (0.2, 0.4)\n",
       "4    (-0.6, 1.0)\n",
       "5     (0.2, 0.4)\n",
       "6     (0.0, 0.0)\n",
       "7     (0.3, 0.6)\n",
       "8     (0.0, 0.0)\n",
       "9     (0.0, 0.0)\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------POLARITY AND SUBJECTIVITY---------------\n",
    "from textblob import TextBlob\n",
    "\n",
    "def pol_and_sub(text, print_results = False):\n",
    "    txtb = TextBlob(text)\n",
    "\n",
    "    if print_results:\n",
    "        print(\"Polarity is: \", round(txtb.sentiment[0], 2), \"and Subjectivity is: \", round(txtb.sentiment[1], 2))\n",
    "    else:\n",
    "        return(round(txtb.sentiment[0], 1), round(txtb.sentiment[1], 1))\n",
    "    \n",
    "df['tweet'].head(10).apply(pol_and_sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
